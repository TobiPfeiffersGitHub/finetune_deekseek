{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%pip install unsloth\n%pip install --force-reinstall --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-27T18:50:31.292752Z","iopub.execute_input":"2025-03-27T18:50:31.293181Z","iopub.status.idle":"2025-03-27T18:50:45.304377Z","shell.execute_reply.started":"2025-03-27T18:50:31.293140Z","shell.execute_reply":"2025-03-27T18:50:45.303251Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: unsloth in /usr/local/lib/python3.10/dist-packages (2025.3.19)\nNote: you may need to restart the kernel to use updated packages.\nCollecting git+https://github.com/unslothai/unsloth.git\n  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-req-build-q_73nvwa\n  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-req-build-q_73nvwa\n  Resolved https://github.com/unslothai/unsloth.git to commit 2ff5dc1a8de1614994a275785b7b64fb4db8cb5d\n  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nBuilding wheels for collected packages: unsloth\n  Building wheel for unsloth (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for unsloth: filename=unsloth-2025.3.19-py3-none-any.whl size=192249 sha256=443cebfccb887677a3cd923a2d3644b86656dc1e228a75aca6ff7fe120a191a1\n  Stored in directory: /tmp/pip-ephem-wheel-cache-0bqpyl0g/wheels/ed/d4/e9/76fb290ee3df0a5fc21ce5c2c788e29e9607a2353d8342fd0d\nSuccessfully built unsloth\nInstalling collected packages: unsloth\n  Attempting uninstall: unsloth\n    Found existing installation: unsloth 2025.3.19\n    Uninstalling unsloth-2025.3.19:\n      Successfully uninstalled unsloth-2025.3.19\nSuccessfully installed unsloth-2025.3.19\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install git+https://github.com/huggingface/transformers.git\n!pip install accelerate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T19:31:13.917219Z","iopub.execute_input":"2025-03-27T19:31:13.917528Z","iopub.status.idle":"2025-03-27T19:31:54.228115Z","shell.execute_reply.started":"2025-03-27T19:31:13.917507Z","shell.execute_reply":"2025-03-27T19:31:54.227045Z"}},"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/huggingface/transformers.git\n  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-35roxt4l\n  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-35roxt4l\n  Resolved https://github.com/huggingface/transformers.git to commit 348f3285c5114159d2ff4933b4b8ae36866d01a7\n  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.51.0.dev0) (3.17.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.51.0.dev0) (0.29.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.51.0.dev0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.51.0.dev0) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.51.0.dev0) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.51.0.dev0) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.51.0.dev0) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers==4.51.0.dev0) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from transformers==4.51.0.dev0) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.51.0.dev0) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers==4.51.0.dev0) (2024.12.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers==4.51.0.dev0) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.51.0.dev0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.51.0.dev0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.51.0.dev0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.51.0.dev0) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.51.0.dev0) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.51.0.dev0) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.51.0.dev0) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.51.0.dev0) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.51.0.dev0) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.51.0.dev0) (2025.1.31)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers==4.51.0.dev0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers==4.51.0.dev0) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers==4.51.0.dev0) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers==4.51.0.dev0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers==4.51.0.dev0) (2024.2.0)\nBuilding wheels for collected packages: transformers\n  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for transformers: filename=transformers-4.51.0.dev0-py3-none-any.whl size=11069858 sha256=1cbdd2340bc177a99b0d9eeae838393049a3858378c737140da4727a4800e6e5\n  Stored in directory: /tmp/pip-ephem-wheel-cache-0ma6h558/wheels/e7/9c/5b/e1a9c8007c343041e61cc484433d512ea9274272e3fcbe7c16\nSuccessfully built transformers\nInstalling collected packages: transformers\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.50.2\n    Uninstalling transformers-4.50.2:\n      Successfully uninstalled transformers-4.50.2\nSuccessfully installed transformers-4.51.0.dev0\nRequirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.2.1)\nRequirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.2)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.2)\nRequirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.6.0)\nRequirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.29.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.5)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.17.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.12.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<3.0.0,>=1.17->accelerate) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<3.0.0,>=1.17->accelerate) (2024.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2025.1.31)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<3.0.0,>=1.17->accelerate) (2024.2.0)\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"import torch\nfrom huggingface_hub import login, create_repo, upload_folder\nfrom transformers import TrainingArguments, AutoTokenizer, AutoModelForCausalLM\nfrom datasets import load_dataset\n\nfrom kaggle_secrets import UserSecretsClient\n\nfrom trl import SFTTrainer\n\nimport wandb\n\nfrom unsloth import FastLanguageModel, is_bfloat16_supported","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T19:20:34.404888Z","iopub.execute_input":"2025-03-27T19:20:34.405232Z","iopub.status.idle":"2025-03-27T19:20:34.409947Z","shell.execute_reply.started":"2025-03-27T19:20:34.405204Z","shell.execute_reply":"2025-03-27T19:20:34.408983Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"wandb.login(key = UserSecretsClient().get_secret(\"wnb_key\"))\nrun = wandb.init(\n    project = 'fine_tune_deepseek_for_customersupport',\n    job_type = 'training',\n    anonymous = 'allow'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T18:55:30.451444Z","iopub.execute_input":"2025-03-27T18:55:30.451799Z","iopub.status.idle":"2025-03-27T18:55:43.307600Z","shell.execute_reply.started":"2025-03-27T18:55:30.451770Z","shell.execute_reply":"2025-03-27T18:55:43.306706Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtobias-pfeiffer\u001b[0m (\u001b[33mtobias-pfeiffer-capgemini\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250327_185537-s5ciapsk</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/tobias-pfeiffer-capgemini/fine_tune_deepseek_for_customersupport/runs/s5ciapsk' target=\"_blank\">gentle-meadow-8</a></strong> to <a href='https://wandb.ai/tobias-pfeiffer-capgemini/fine_tune_deepseek_for_customersupport' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/tobias-pfeiffer-capgemini/fine_tune_deepseek_for_customersupport' target=\"_blank\">https://wandb.ai/tobias-pfeiffer-capgemini/fine_tune_deepseek_for_customersupport</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/tobias-pfeiffer-capgemini/fine_tune_deepseek_for_customersupport/runs/s5ciapsk' target=\"_blank\">https://wandb.ai/tobias-pfeiffer-capgemini/fine_tune_deepseek_for_customersupport/runs/s5ciapsk</a>"},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"### Model Config","metadata":{}},{"cell_type":"code","source":"MAX_SEQ_LENGTH = 2048\nLOAD_IN_4BIT = True # reduce size to enable local development\nDTYPE = None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T18:55:51.717726Z","iopub.execute_input":"2025-03-27T18:55:51.718135Z","iopub.status.idle":"2025-03-27T18:55:51.722665Z","shell.execute_reply.started":"2025-03-27T18:55:51.718111Z","shell.execute_reply":"2025-03-27T18:55:51.721929Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"model, tokenizer = (\n    FastLanguageModel\n    .from_pretrained(\n        model_name = 'unsloth/DeepSeek-R1-Distill-Llama-8B',\n        max_seq_length = MAX_SEQ_LENGTH,\n        dtype = DTYPE,\n        load_in_4bit = LOAD_IN_4BIT,\n        token = UserSecretsClient().get_secret(\"hf_key\")\n    )\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T18:55:58.001039Z","iopub.execute_input":"2025-03-27T18:55:58.001459Z","iopub.status.idle":"2025-03-27T18:57:45.744540Z","shell.execute_reply.started":"2025-03-27T18:55:58.001422Z","shell.execute_reply":"2025-03-27T18:57:45.743851Z"}},"outputs":[{"name":"stdout","text":"==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.50.2.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/5.96G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2e7794af4da4425932a8d90aba4a0bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/236 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7d296e47da64d8b848088844bd5ef60"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/53.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"710d8efe951545e494aa93809ef82714"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"525915d6416847479799912bbe76330a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9dd993f615c4082a1eb25920b51213d"}},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"system_prompt = \"\"\"\nYou are a helpful customer support assistant. Read the inquiry and generate a professional response.\n\nCustomer: \"{}\"\n\nResponse:\n<think>Understand the request and generate a courteous, helpful reply.\n<response>\"{}\"\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T19:00:53.203327Z","iopub.execute_input":"2025-03-27T19:00:53.203696Z","iopub.status.idle":"2025-03-27T19:00:53.208765Z","shell.execute_reply.started":"2025-03-27T19:00:53.203669Z","shell.execute_reply":"2025-03-27T19:00:53.207870Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"load dataset for finetuning","metadata":{}},{"cell_type":"code","source":"dataset = load_dataset(\"AabirDey/job-queries-and-customer-service\")\nEOS_TOKEN = tokenizer.eos_token","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T19:00:14.574958Z","iopub.execute_input":"2025-03-27T19:00:14.575356Z","iopub.status.idle":"2025-03-27T19:00:18.759272Z","shell.execute_reply.started":"2025-03-27T19:00:14.575325Z","shell.execute_reply":"2025-03-27T19:00:18.758378Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/36.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64945bab3d2b4874a2099f74979d0cd2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train.csv:   0%|          | 0.00/15.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5366ac79c2eb4145bd4b94548e28d150"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test.csv:   0%|          | 0.00/3.77M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5af26e3b76284f0795729a40c5ff5d26"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/23551 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f0aa4ddadab4c7ba1ed568a464fe01a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/5888 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"edde521109cf4219957ce0e836ba3b52"}},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"# adjust data for system prompt\n\ndef format_for_finetuning(example):\n    _inputs = example['instruction']\n    _outputs = example['output']\n    formatted = []\n    for i, j in zip(_inputs, _outputs):\n        formatted_text = system_prompt.format(i, j) + EOS_TOKEN\n        formatted.append(formatted_text)\n    return {\"text\": formatted}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T19:00:20.353352Z","iopub.execute_input":"2025-03-27T19:00:20.353823Z","iopub.status.idle":"2025-03-27T19:00:20.360889Z","shell.execute_reply.started":"2025-03-27T19:00:20.353782Z","shell.execute_reply":"2025-03-27T19:00:20.359807Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"finetune_dataset = dataset.map(format_for_finetuning, batched=True)\n\n# check the output of format_for_finetuning()\nprint(finetune_dataset['train']['text'][0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T19:00:57.138836Z","iopub.execute_input":"2025-03-27T19:00:57.139157Z","iopub.status.idle":"2025-03-27T19:00:57.552492Z","shell.execute_reply.started":"2025-03-27T19:00:57.139134Z","shell.execute_reply":"2025-03-27T19:00:57.551498Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/23551 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c713cf4f0b7541469d413fee2ef5c843"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5888 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85c58fe1ad144e85b83629b9dd573f46"}},"metadata":{}},{"name":"stdout","text":"\nYou are a helpful customer support assistant. Read the inquiry and generate a professional response.\n\nCustomer: \"would it be possible to file a damn customer reclamation?\"\n\nResponse:\n<think>Understand the request and generate a courteous, helpful reply.\n<response>\"I apologize for any frustration or inconvenience you may have experienced. I understand that you would like to file a customer reclamation. Our company takes customer complaints seriously, and I assure you that I will do my best to assist you with this matter. To better understand your situation, could you please provide me with more details about the issue you are facing? This will help me guide you through the process and ensure that your concerns are addressed appropriately. Thank you for reaching out to us, and we appreciate your patience as we work towards a resolution.\"\n<｜end▁of▁sentence｜>\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"### Finetuning & LoRA","metadata":{}},{"cell_type":"markdown","source":"https://huggingface.co/blog/Andyrasika/finetune-unsloth-qlora","metadata":{}},{"cell_type":"code","source":"model_lora = (\n    FastLanguageModel\n    .get_peft_model(\n        model,\n        r = 16,\n        target_modules = [\n            \"q_proj\",\n            \"k_proj\",\n            \"v_proj\",\n            \"o_proj\",\n            \"gate_proj\",\n            \"up_proj\",\n            \"down_proj\"\n        ],\n        lora_alpha = 16,\n        lora_dropout = 0,\n        bias = \"none\",\n        use_gradient_checkpointing = 'unsloth',\n        random_state = 420,\n        use_rslora = False,\n        loftq_config = None\n    )\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T19:01:04.438167Z","iopub.execute_input":"2025-03-27T19:01:04.438471Z","iopub.status.idle":"2025-03-27T19:01:10.363952Z","shell.execute_reply.started":"2025-03-27T19:01:04.438448Z","shell.execute_reply":"2025-03-27T19:01:10.363017Z"}},"outputs":[{"name":"stderr","text":"Unsloth 2025.3.19 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"from trl import SFTTrainer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T19:02:26.882352Z","iopub.execute_input":"2025-03-27T19:02:26.882712Z","iopub.status.idle":"2025-03-27T19:02:26.887551Z","shell.execute_reply.started":"2025-03-27T19:02:26.882685Z","shell.execute_reply":"2025-03-27T19:02:26.886803Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"trainer = SFTTrainer(\n    model = model_lora,\n    tokenizer = tokenizer,\n    train_dataset = finetune_dataset[\"train\"],\n    dataset_text_field = \"text\",\n    max_seq_length = MAX_SEQ_LENGTH,\n    dataset_num_proc = 2,\n\n    args = TrainingArguments(\n        per_device_train_batch_size = 2,\n        gradient_accumulation_steps = 4,\n        num_train_epochs = 1,\n        warmup_steps = 5,\n        max_steps = 50,\n        learning_rate = 2e-4,\n        fp16 = not is_bfloat16_supported(),\n        bf16 = is_bfloat16_supported(),\n        logging_steps = 10,\n        optim = \"adamw_8bit\",\n        weight_decay = 0.01,\n        lr_scheduler_type = \"linear\",\n        seed = 420,\n        output_dir = \"outputs\"\n    )\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T19:02:29.882151Z","iopub.execute_input":"2025-03-27T19:02:29.882450Z","iopub.status.idle":"2025-03-27T19:02:38.553315Z","shell.execute_reply.started":"2025-03-27T19:02:29.882428Z","shell.execute_reply":"2025-03-27T19:02:38.552518Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Unsloth: Tokenizing [\"text\"] (num_proc=2):   0%|          | 0/23551 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"625ea8a3d3c74e43879536be807e85ab"}},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"trainer_stats = trainer.train()\n\nwandb.finish()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T19:02:51.323864Z","iopub.execute_input":"2025-03-27T19:02:51.324190Z","iopub.status.idle":"2025-03-27T19:15:23.368337Z","shell.execute_reply.started":"2025-03-27T19:02:51.324164Z","shell.execute_reply":"2025-03-27T19:15:23.367443Z"}},"outputs":[{"name":"stderr","text":"==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n   \\\\   /|    Num examples = 23,551 | Num Epochs = 1 | Total steps = 50\nO^O/ \\_/ \\    Batch size per device = 4 | Gradient accumulation steps = 4\n\\        /    Data Parallel GPUs = 1 | Total batch size (4 x 4 x 1) = 16\n \"-____-\"     Trainable parameters = 41,943,040/8,000,000,000 (0.52% trained)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","output_type":"stream"},{"name":"stdout","text":"Unsloth: Will smartly offload gradients to save VRAM!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [50/50 12:00, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>2.161300</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>1.226400</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>1.043900</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.968400</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>0.937600</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁▃▅▆██</td></tr><tr><td>train/global_step</td><td>▁▃▅▆██</td></tr><tr><td>train/grad_norm</td><td>█▃▁▃▂</td></tr><tr><td>train/learning_rate</td><td>█▆▅▃▁</td></tr><tr><td>train/loss</td><td>█▃▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>total_flos</td><td>9450549998616576.0</td></tr><tr><td>train/epoch</td><td>0.03397</td></tr><tr><td>train/global_step</td><td>50</td></tr><tr><td>train/grad_norm</td><td>0.47531</td></tr><tr><td>train/learning_rate</td><td>0</td></tr><tr><td>train/loss</td><td>0.9376</td></tr><tr><td>train_loss</td><td>1.26749</td></tr><tr><td>train_runtime</td><td>748.5969</td></tr><tr><td>train_samples_per_second</td><td>1.069</td></tr><tr><td>train_steps_per_second</td><td>0.067</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">gentle-meadow-8</strong> at: <a href='https://wandb.ai/tobias-pfeiffer-capgemini/fine_tune_deepseek_for_customersupport/runs/s5ciapsk' target=\"_blank\">https://wandb.ai/tobias-pfeiffer-capgemini/fine_tune_deepseek_for_customersupport/runs/s5ciapsk</a><br> View project at: <a href='https://wandb.ai/tobias-pfeiffer-capgemini/fine_tune_deepseek_for_customersupport' target=\"_blank\">https://wandb.ai/tobias-pfeiffer-capgemini/fine_tune_deepseek_for_customersupport</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250327_185537-s5ciapsk/logs</code>"},"metadata":{}}],"execution_count":22},{"cell_type":"markdown","source":"### Saving Model","metadata":{}},{"cell_type":"code","source":"login(UserSecretsClient().get_secret(\"hf_key\"))\n\nrepo_name = \"tobinho1234/deep-seek-lora-customer-support\"\nlocal_model_path = \"/kaggle/working/outputs/checkpoint-50\"\n\ncreate_repo(repo_name, exist_ok = True)\nupload_folder(\n    repo_id = repo_name,\n    folder_path = local_model_path,\n    path_in_repo = \".\",\n    commit_message = \"Upload LoRA fine-tuned adapter and tokenizer\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T19:18:16.175004Z","iopub.execute_input":"2025-03-27T19:18:16.175359Z","iopub.status.idle":"2025-03-27T19:18:25.437376Z","shell.execute_reply.started":"2025-03-27T19:18:16.175332Z","shell.execute_reply":"2025-03-27T19:18:25.436560Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"scaler.pt:   0%|          | 0.00/988 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3f07993ae3449818549e95284c18a44"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"optimizer.pt:   0%|          | 0.00/85.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ae15ff49789410d96f207c3bd81c2e6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Upload 7 LFS files:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0853a87b85324ecf915ce052002e31cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"rng_state.pth:   0%|          | 0.00/14.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43b97f4a9d634d578065b55ef168f945"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/168M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac51b8fc90e9414a90d0654f5ccf8367"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"scheduler.pt:   0%|          | 0.00/1.06k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b8c5733e427430f90b1eb9eebc8e8f6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a41a22331264e62aba21a7ff3446d1f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"training_args.bin:   0%|          | 0.00/5.62k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1dbed8245dd14832b1ead9d0f1938b7d"}},"metadata":{}},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/tobinho1234/deep-seek-lora-customer-support/commit/571efcaed4ae5db5b3225c519a58779c9b3ffb94', commit_message='Upload LoRA fine-tuned adapter and tokenizer', commit_description='', oid='571efcaed4ae5db5b3225c519a58779c9b3ffb94', pr_url=None, repo_url=RepoUrl('https://huggingface.co/tobinho1234/deep-seek-lora-customer-support', endpoint='https://huggingface.co', repo_type='model', repo_id='tobinho1234/deep-seek-lora-customer-support'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":25}]}